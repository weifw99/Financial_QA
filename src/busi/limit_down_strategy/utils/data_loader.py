# utils/data_loader.py
# å°è£…è‚¡ç¥¨ä¸æŒ‡æ•°çš„ CSV æ•°æ®åŠ è½½ï¼Œæ³¨å…¥è‡ªå®šä¹‰å­—æ®µï¼šå¸‚å€¼ã€åˆ©æ¶¦ã€è¥æ”¶ã€ST
import os
from datetime import timedelta
from pathlib import Path

import numpy as np
import pandas as pd
import backtrader as bt

class CustomPandasData(bt.feeds.PandasData):
    """
    è‡ªå®šä¹‰æ•°æ®ç±»ï¼ŒåŒ…å«ï¼šå¸‚å€¼ã€å¸‚ç›ˆç‡ã€åˆ©æ¶¦ã€è¥æ”¶ã€æ˜¯å¦STæ ‡è®°ç­‰åŸºæœ¬é¢æ•°æ®
    éœ€è¦ä¿è¯dfä¸­æœ‰ä»¥ä¸‹å­—æ®µï¼šdatetime, open, high, low, close, volume, mv, profit, revenue, is_st
    """

    lines = ('amount', 'turn', 'mv', 'lt_mv', 'lt_share_rate',  'is_st', 'profit_ttm_y', 'profit_y', 'revenue_y', 'roeAvg_y', 'profit_ttm_q', 'profit_q', 'revenue_single_q', 'roeAvg_q', 'price_limit')
    params = (
        ('amount', -1),
        ('turn', -1),
        ('mv', -1),
        ('lt_mv', -1),
        ('lt_share_rate', -1),
        ('is_st', -1),# 0 or 1 è¡¨ç¤ºæ˜¯å¦ST
        ('profit_ttm_y', -1),
        ('profit_y', -1),
        ('revenue_y', -1),
        ('roeAvg_y', -1),  #

        ('profit_ttm_q', -1),
        ('profit_q', -1),
        ('revenue_single_q', -1),
        ('roeAvg_q', -1),  #
        ('price_limit', -1),  #

        ('dtformat', '%Y-%m-%d'),
    )
import pandas as pd
import numpy as np

def calc_MBRevenue_single_via_rule(df: pd.DataFrame) -> pd.DataFrame:
    """
    æŒ‰ç…§å›ºå®šè§„åˆ™è¡¥å…… MBRevenue_singleï¼š
    - Q1ï¼ˆ3æœˆï¼‰ï¼šQ2å€¼ / 2
    - Q2ï¼ˆ6æœˆï¼‰ï¼šQ2å€¼ / 2
    - Q3ï¼ˆ9æœˆï¼‰ï¼š(Q4 - Q2) / 2
    - Q4ï¼ˆ12æœˆï¼‰ï¼š(Q4 - Q2) / 2

    è¦æ±‚ df åŒ…å« ['statDate', 'MBRevenue']ï¼Œæ¯è¡Œæ˜¯ä¸€ä¸ªå­£åº¦è®°å½•ã€‚
    """

    df = df.copy()
    df['statDate'] = pd.to_datetime(df['statDate'])
    df = df.sort_values('statDate').reset_index(drop=True)
    df['year'] = df['statDate'].dt.year
    df['month'] = df['statDate'].dt.month
    df['MBRevenue'] = pd.to_numeric(df['MBRevenue'], errors='coerce')
    df['MBRevenue_single'] = np.nan

    for year, group in df.groupby('year'):
        group = group.set_index('month')

        try:
            q2_val = group.at[6, 'MBRevenue']
            q4_val = group.at[12, 'MBRevenue']

            # Q1ï¼ˆ3æœˆï¼‰ï¼šè‹¥å­˜åœ¨06-30ï¼ŒQ2å€¼ / 2
            if 3 in group.index:
                idx = df[(df['year'] == year) & (df['month'] == 3)].index[0]
                if pd.notna(q2_val):
                    df.at[idx, 'MBRevenue_single'] = q2_val / 2

            # Q2ï¼ˆ6æœˆï¼‰ï¼šQ2å€¼ / 2
            if 6 in group.index:
                idx = df[(df['year'] == year) & (df['month'] == 6)].index[0]
                if pd.notna(q2_val):
                    df.at[idx, 'MBRevenue_single'] = q2_val / 2

            # Q3/Q4ï¼šå¦‚æœ Q2/Q4 éƒ½æœ‰å€¼ï¼Œåˆ™ Q3/Q4 = (Q4 - Q2) / 2
            if pd.notna(q2_val) and pd.notna(q4_val):
                delta = q4_val - q2_val

                if 9 in group.index:
                    idx = df[(df['year'] == year) & (df['month'] == 9)].index[0]
                    df.at[idx, 'MBRevenue_single'] = delta / 2

                if 12 in group.index:
                    idx = df[(df['year'] == year) & (df['month'] == 12)].index[0]
                    df.at[idx, 'MBRevenue_single'] = delta / 2

        except KeyError:
            continue  # æœ¬å¹´å­£åº¦æ•°æ®ä¸å…¨ï¼Œè·³è¿‡

    return df.drop(columns=['year', 'month'])
def process_financial_data(financial_df: pd.DataFrame):
    """
    è¾“å…¥åŸå§‹è´¢æŠ¥æ•°æ®ï¼Œè¾“å‡ºï¼š
    - å¹´åº¦è´¢æŠ¥ï¼ˆæ·»åŠ  apply_year å­—æ®µï¼‰
    - å­£åº¦è´¢æŠ¥ï¼ˆæ·»åŠ  apply_quarter å­—æ®µï¼‰
    """
    df = calc_MBRevenue_single_via_rule( financial_df )
    df.rename(columns={'netProfit': 'profit', 'MBRevenue': 'revenue','MBRevenue_single': 'revenue_single', }, inplace=True)
    df['revenue'] = df['revenue'].ffill()
    df['pubDate'] = pd.to_datetime(df['pubDate'])
    df['statDate'] = pd.to_datetime(df['statDate'])

    # å½’å±æ¯å…¬å¸è‚¡ä¸œçš„å‡€åˆ©æ¶¦TTM
    # epsTTM	æ¯è‚¡æ”¶ç›Š	å½’å±æ¯å…¬å¸è‚¡ä¸œçš„å‡€åˆ©æ¶¦TTM/æœ€æ–°æ€»è‚¡æœ¬
    df['profit_ttm'] = df['totalShare'] * df['epsTTM']
    # pubDate	å…¬å¸å‘å¸ƒè´¢æŠ¥çš„æ—¥æœŸ
    # roeAvg	å‡€èµ„äº§æ”¶ç›Šç‡(å¹³å‡)(%)	å½’å±æ¯å…¬å¸è‚¡ä¸œå‡€åˆ©æ¶¦/[(æœŸåˆå½’å±æ¯å…¬å¸è‚¡ä¸œçš„æƒç›Š+æœŸæœ«å½’å±æ¯å…¬å¸è‚¡ä¸œçš„æƒç›Š)/2]*100%
    # statDate	è´¢æŠ¥ç»Ÿè®¡çš„å­£åº¦çš„æœ€åä¸€å¤©, æ¯”å¦‚2017-03-31, 2017-06-30
    # netProfit	å‡€åˆ©æ¶¦(å…ƒ)
    # MBRevenue	ä¸»è¥è¥ä¸šæ”¶å…¥(å…ƒ)
    # mv å¸‚å€¼
    # ä½¿ç”¨ pd.merge_asof å®ç°æŒ‰æ—¶é—´å‘å‰å¡«å……åŒ¹é…
    # profit_ttm å½’å±æ¯å…¬å¸è‚¡ä¸œçš„å‡€åˆ©æ¶¦TTM

    # å¹´åº¦åˆ¤æ–­ï¼š12æœˆ31æ—¥çš„ statDate ä¸ºå¹´æŠ¥
    is_annual = df['statDate'].dt.month == 12

    annual_df = df[is_annual].copy()
    quarterly_df = df.copy()

    # æ·»åŠ å¹´åº¦è´¢æŠ¥é€‚ç”¨å¹´
    annual_df['apply_year'] = annual_df['statDate'].dt.year + 1

    # æ·»åŠ å­£åº¦è´¢æŠ¥é€‚ç”¨å­£åº¦ï¼ˆå­£åº¦æœ«æ—¥æœŸï¼‰
    def get_next_quarter(stat_date):
        y, m = stat_date.year, stat_date.month
        if m <= 3:
            return pd.Timestamp(f"{y}-06-30")
        elif m <= 6:
            return pd.Timestamp(f"{y}-09-30")
        elif m <= 9:
            return pd.Timestamp(f"{y}-12-31")
        else:
            return pd.Timestamp(f"{y+1}-03-31")

    quarterly_df['apply_quarter'] = quarterly_df['statDate'].apply(get_next_quarter)

    # åç¼€å­—æ®µå
    suffix_q = {col: f"{col}_q" for col in df.columns if col not in ['code', 'apply_quarter', 'statDate', 'pubDate']}
    suffix_y = {col: f"{col}_y" for col in df.columns if col not in ['code', 'apply_year', 'statDate', 'pubDate']}

    # é‡å‘½åå­—æ®µï¼ˆä¾¿äºåç»­åˆå¹¶æ—¶åŒºåˆ†ï¼‰
    quarterly_df = quarterly_df.rename(columns=suffix_q)
    annual_df = annual_df.rename(columns=suffix_y)

    return quarterly_df, annual_df


def merge_with_stock(stock_df: pd.DataFrame, quarterly_df: pd.DataFrame, annual_df: pd.DataFrame, df_shares: pd.DataFrame):
    """
    stock_df åŒ…å«å­—æ®µ ['code', 'trade_date']ï¼ˆdatetime ç±»å‹ï¼‰
    åˆå¹¶å¹´åº¦ä¸å­£åº¦è´¢æŠ¥æ•°æ®ï¼Œç”Ÿæˆå®Œæ•´å¯¹é½ DataFrame
    """

    df = stock_df.copy()
    df['date'] = pd.to_datetime(df['date'])

    # è·å–å­£åº¦æœ«æ—¥æœŸ
    def get_quarter_end(date):
        y, m = date.year, date.month
        if m <= 3:
            return pd.Timestamp(f"{y}-03-31")
        elif m <= 6:
            return pd.Timestamp(f"{y}-06-30")
        elif m <= 9:
            return pd.Timestamp(f"{y}-09-30")
        else:
            return pd.Timestamp(f"{y}-12-31")

    df['quarter_end'] = df['date'].apply(get_quarter_end)
    df['year'] = df['date'].dt.year

    # 1. åˆå¹¶å­£åº¦æ•°æ®
    df = df.merge(
        quarterly_df,
        how='left',
        left_on=['code', 'quarter_end'],
        right_on=['code', 'apply_quarter']
    )

    # 2. åˆå¹¶å¹´åº¦æ•°æ®
    df = df.merge(
        annual_df,
        how='left',
        left_on=['code', 'year'],
        right_on=['code', 'apply_year']
    )

    # å‡è®¾ df_stock æ˜¯è‚¡ç¥¨è¡Œæƒ…æ•°æ®ï¼Œæœ‰ 'date' åˆ—
    # å‡è®¾ df_shares æ˜¯æ€»è‚¡æœ¬æ•°æ®ï¼Œæœ‰ 'date' å’Œ 'totalShare' åˆ—

    if df_shares is not None:
        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯ datetime ç±»å‹
        df['date'] = pd.to_datetime(df['date'])
        df_shares['date'] = pd.to_datetime(df_shares['date'])

        # æŒ‰æ—¥æœŸæ’åºï¼ˆmerge_asof è¦æ±‚å…ˆæ’åºï¼‰
        df = df.sort_values('date')
        df_shares = df_shares.sort_values('date')

        # å‘å‰å¡«å……æœ€è¿‘çš„æ€»è‚¡æ•°ï¼ˆä¸æ™šäºè¯¥äº¤æ˜“æ—¥ï¼‰
        df_merged = pd.merge_asof(
            df,
            df_shares,
            on='date',
            direction='backward'  # å‘å‰æŸ¥æ‰¾æœ€è¿‘çš„è‚¡æœ¬æ•°æ®
        )

        return df_merged
    else:
        return df


def merge_stock_with_industry(stock_df: pd.DataFrame, industry_df: pd.DataFrame) -> pd.DataFrame:
    """
    å°†è‚¡ç¥¨äº¤æ˜“æ•°æ®ä¸è¡Œä¸šåˆ†ç±»æ•°æ®è¿›è¡Œå·¦å…³è”ï¼ˆä¿ç•™åŸå§‹ codeï¼Œå¹¶åˆ›å»ºåŒ¹é…ç”¨çš„ codeï¼‰

    å‚æ•°ï¼š
        stock_df: è‚¡ç¥¨äº¤æ˜“æ•°æ®ï¼ŒåŒ…å« codeï¼ˆæ ¼å¼å¦‚ sh.000001ï¼‰
        industry_dir: è¡Œä¸šæ•°æ® CSV æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œæ–‡ä»¶ç»“æ„ä¸º code,name,industry_code,industry_name

    è¿”å›ï¼š
        åˆå¹¶åçš„ DataFrameï¼ˆé™„åŠ å­—æ®µï¼šindustry_code, industry_nameï¼‰
    """

    # æå–è‚¡ç¥¨åŸå§‹ codeï¼Œå¹¶è½¬ä¸º 6 ä½åŒ¹é…å€¼
    stock_df = stock_df.copy()
    stock_df['stock_code_raw'] = stock_df['code']  # åŸå§‹å¦‚ sh.000002

    stock_df['stock_code_raw'] = stock_df['stock_code_raw'].apply(lambda x: str(x)[-6:])  # æå– 000002 ç”¨äºåŒ¹é…

    industry_df.rename(columns={'code': 'code_indu'}, inplace=True)
    # 4. åˆå¹¶è¡Œä¸šæ•°æ®ï¼ˆå·¦è¿æ¥ï¼‰
    merged_df = pd.merge(
        stock_df,
        industry_df[['code_indu', 'industry_code', 'industry_name']],
        how='left',
        left_on='stock_code_raw',
        right_on='code_indu'
    )

    merged_df.fillna(0, inplace=True)

    return merged_df


def load_stock_data(from_idx, to_idx):
    """
    æ‰¹é‡åŠ è½½ data_dir ä¸‹çš„æ‰€æœ‰ CSV æ–‡ä»¶ï¼Œè¿”å›æ•°æ®åˆ—è¡¨
    æ–‡ä»¶åå°†ä½œä¸ºæ•°æ®åç§°æ³¨å…¥ï¼Œå¦‚ '600000.csv' -> data._name = '600000'
    :param data_dir: åŒ…å«CSVçš„è·¯å¾„
    :return: list of data feeds
    """
    zz_code_data_paths = [
        # '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/raw/index/ä¸­å°æ¿æŒ‡æ•°-ä¸­å°100-399005.csv',
        '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/raw/index/ä¸­å°ç»¼æŒ‡-399101.csv',
        # '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/raw/index/ä¸­è¯1000-000852.csv',
        # '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/raw/index/ä¸­è¯2000-932000.csv',
        # '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/raw/index/å¾®ç›˜è‚¡-BK1158.csv',
    ]
    zz_code_list = []
    for zz_code_data_path in zz_code_data_paths:
        if not os.path.exists(zz_code_data_path):
            print(f'{zz_code_data_path} ä¸å­˜åœ¨')
            continue
        zz_code_df = pd.read_csv(zz_code_data_path)
        zz_code_list += zz_code_df['type'].tolist()

    datas = []

    base_data_path = '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data'
    zh_data_dir = Path(base_data_path) / 'market'
    financial_data_dir = Path(base_data_path).parent / 'zh_data/financial'
    board_industry_dir = Path(base_data_path).parent / 'zh_data/industry/board_industry'


    # 1. æ‰¾åˆ°è¡Œä¸šç›®å½•ä¸­æœ€æ–°çš„CSVæ–‡ä»¶
    files = [f for f in os.listdir(board_industry_dir) if f.endswith('.csv')]
    if not files:
        raise FileNotFoundError(f"âš ï¸ è¡Œä¸šç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°CSVæ–‡ä»¶: {board_industry_dir}")
    files.sort(key=lambda f: os.path.getmtime(os.path.join(board_industry_dir, f)), reverse=True)
    latest_file = os.path.join(board_industry_dir, files[0])
    print(f"ğŸ“„ ä½¿ç”¨è¡Œä¸šæ–‡ä»¶: {latest_file}")

    # 2. è¯»å–è¡Œä¸šæ•°æ®
    industry_df = pd.read_csv(latest_file, dtype={'code': str})
    industry_df = industry_df[['code', 'name', 'industry_code', 'industry_name']]

    # è·å–æ‰€æœ‰æ—¶é—´æ•°æ®ï¼Œ ä½¿ç”¨000001.csv
    pdf = pd.read_csv(f'{zh_data_dir}/sh.000001/daily.csv')
    pdf['date'] = pd.to_datetime(pdf['date'])

    from_date = from_idx - timedelta(days=40)
    pdf = pdf[pdf['date'] >= from_date]
    data = pd.DataFrame(index=pdf['date'].unique())
    data = data.sort_index()

    select_cols = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', ]
    add_cols = ['industry_name', 'amount', 'turn', 'mv', 'lt_mv', 'lt_share_rate',   'is_st', 'profit_ttm_y', 'profit_y', 'revenue_y', 'roeAvg_y', 'profit_ttm_q', 'profit_q', 'revenue_single_q', 'roeAvg_q', 'openinterest', ]
    # åŠ è½½ SZ510880 SH159300
    etf_list = ['SZ510880', 'SH159919', 'SZ510050', 'SZ588000', 'SZ511880']
    etf_path = '/Users/dabai/liepin/study/llm/Financial_QA/src/busi/etf_/data/etf_trading/daily'
    for etf_code in etf_list:
        etf_df = pd.read_csv(f'{etf_path}/{etf_code}.csv')
        # é€‰æ‹©éœ€è¦çš„åˆ—
        etf_df = etf_df[select_cols]
        for col in add_cols:
            if col not in etf_df.columns:
                etf_df[col] = 0
        etf_df['date'] = pd.to_datetime(etf_df['date'])
        etf_df.set_index('date', inplace=True)  # è®¾ç½® datetime ä¸ºç´¢å¼•
        etf_df = etf_df.sort_index()
        data_ = pd.merge(data, etf_df, left_index=True, right_index=True, how='left')
        data_.fillna(0, inplace=True)
        data_ = data_.sort_index()  # âœ… å¼ºåˆ¶å‡åº
        pandas_data = CustomPandasData(dataname=data_,
                                       fromdate=from_idx,
                                       todate=to_idx,
                                       timeframe=bt.TimeFrame.Days,
                                       name=f'etf_{etf_code}')
        datas.append(pandas_data)


    index_list =['csi932000', 'sz399101' , 'sh000905', 'sh000852', 'sh000046', 'sz399005', 'sz399008', 'sz399401',
                 'sz399649','sz399663','sz399377','sh000046','sz399408','sz399401','sh000991' ,
                 'sh000852', 'sz399004', 'sh000905', 'sz399006',
                 'sz399693']
    # è·å–æŒ‡æ•°æ•°æ®
    zz_path = '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/index'

    for index_code in index_list:

        zz_df = pd.read_csv(f'{zz_path}/{index_code}.csv')
        # é€‰æ‹©éœ€è¦çš„åˆ—
        zz_df = zz_df[select_cols[:-1]]
        for col in add_cols:
            if col not in zz_df.columns:
                zz_df[col] = 0
        zz_df['date'] = pd.to_datetime(zz_df['date'])
        zz_df.set_index('date', inplace=True)  # è®¾ç½® datetime ä¸ºç´¢å¼•
        zz_df = zz_df.sort_index()
        data_ = pd.merge(data, zz_df, left_index=True, right_index=True, how='left')
        data_.fillna(0, inplace=True)
        data_ = data_.sort_index()  # âœ… å¼ºåˆ¶å‡åº
        pandas_data = CustomPandasData(dataname=data_,
                                       fromdate=from_idx,
                                       todate=to_idx,
                                       timeframe=bt.TimeFrame.Days,
                                       name=index_code)
        datas.append(pandas_data)

    temp_stock_list = ['sh.000300',  'sh.000016', 'sh.000852', 'BK1158', ]
    for i, stock_file in enumerate(os.listdir(zh_data_dir)):
        # if i > 500:
        #     break

        # æµ‹è¯•
        # if len(datas) >100 and stock_file  not in temp_stock_list:
        #     continue

        # ä½¿ç”¨æŒ‡æ•°æˆåˆ†è‚¡è‚¡ç¥¨å›æµ‹
        if stock_file not in zz_code_list and stock_file not in temp_stock_list:
            print(f'è¿‡æ»¤éæŒ‡æ•°æˆåˆ†è‚¡è‚¡ç¥¨: {stock_file}')
            continue # 0.1945 sz399101æˆåˆ†è‚¡,
            # æŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ® 0.10   ä¸­è¯1000-000852ï¼Œä¸­è¯2000-932000
            # æŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ® 0.158  ä¸­å°ç»¼æŒ‡-399101,ä¸­è¯1000-000852ï¼Œä¸­è¯2000-932000
            # æŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ® 0.1945  ä¸­å°ç»¼æŒ‡-399101,ä¸­è¯1000-000852
            # æŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ® 0.158  ä¸­å°ç»¼æŒ‡-399101,ä¸­è¯2000-932000
            # æŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ® 0.10,ä¸­è¯2000-932000
        # 0.2137ï¼Œå…¨éƒ¨æ•°æ®
        # è¿‡æ»¤åˆ›ä¸šæ¿/ç§‘åˆ›æ¿/åŒ—äº¤æ‰€è‚¡ç¥¨
        if ('.30' in stock_file
                or '.68' in stock_file
                or '.8' in stock_file
                or '.4' in stock_file):
            print(f'è¿‡æ»¤åˆ›ä¸šæ¿/ç§‘åˆ›æ¿/åŒ—äº¤æ‰€è‚¡ç¥¨: {stock_file}')
            continue

        print(f'{i}/{stock_file}')
        # file_path = f'{zh_data_dir}/{stock_file}/daily.csv'
        file_path_a = f'{zh_data_dir}/{stock_file}/daily_a.csv'

        # è·å–è´¢åŠ¡ç›ˆåˆ©ä¿¡æ¯
        financial_path = f'{financial_data_dir}/{stock_file}/income.csv'
        income_gbjg_path = f'{financial_data_dir}/{stock_file}/income_gbjg.csv'
        if os.path.exists(file_path_a):
            df = pd.read_csv(file_path_a)
            if 'code' not in df.columns:
                print(f'{stock_file} ç¼ºå°‘åˆ—: {col}')
                df['code'] = stock_file

            # df = merge_stock_with_industry(df, industry_df)

            # è¿‡æ»¤ä¸Šå¸‚æ—¶é—´å¤ªçŸ­çš„è‚¡ç¥¨ ï¼ˆA è‚¡ä¸€å¹´äº¤æ˜“æ—¶é—´243å¤©ï¼‰ï¼Œå–ä¸Šå¸‚ä¸€å¹´å¤šçš„è‚¡ç¥¨
            if len(df) < 275:
                print(f'{stock_file} ä¸Šå¸‚äº¤æ˜“æ—¶é—´å¤ªçŸ­ï¼Œäº¤æ˜“çš„å¤©æ•°: {len(df)}ï¼Œå¿½ç•¥è¯¥è‚¡ç¥¨')
                continue

            # df_a = pd.read_csv(file_path_a)[['date','close']]
            # df_a.rename(columns={'close': 'close_1'}, inplace=True)

            # df = pd.merge(df, df_a, on='date', how='inner')
            df['close_1'] = df['close']

            # ä½¿ç”¨åå¤æƒä»·æ ¼ï¼Œfactorå‡è®¾ç½®ä¸º1ï¼Œ å›æµ‹ä½¿ç”¨è¯¥å› å­
            df['factor'] = 1.0
            # ç¡®ä¿ date åˆ—ä¸º datetime ç±»å‹å¹¶æ’åº
            df['date'] = pd.to_datetime(df['date'])
            df_sorted = df.sort_values('date')
            df_sorted.rename(columns={'isST': 'is_st', }, inplace=True)

            if os.path.exists(financial_path):

                financial_df = pd.read_csv(financial_path)
                if os.path.exists(income_gbjg_path):
                    income_gbjg_df = pd.read_csv(income_gbjg_path)[['å˜æ›´æ—¥æœŸ','æ€»è‚¡æœ¬', 'å·²ä¸Šå¸‚æµé€šAè‚¡']]
                    income_gbjg_df.rename(columns={'å˜æ›´æ—¥æœŸ': 'date', 'æ€»è‚¡æœ¬': 'totalShare_new', 'å·²ä¸Šå¸‚æµé€šAè‚¡': 'liqaShare_a'}, inplace=True)
                else:
                    income_gbjg_df = None

                quarterly_df, annual_df = process_financial_data(financial_df)

                df_temp = merge_with_stock(df_sorted, quarterly_df, annual_df, income_gbjg_df)
                if 'totalShare_new' not in df_temp.columns:
                    df_temp['totalShare_new'] = df_temp['totalShare_q']

                if 'liqaShare_a' not in df_temp.columns:
                    df_temp['liqaShare_a'] = df_temp['liqaShare_q']

                df2_sorted = df_temp.sort_values('date').ffill().dropna()

                df = df2_sorted

                df['mv'] = df['totalShare_new'] * df['close_1'] # å¸‚å€¼ = æ€»è‚¡æœ¬ * æ”¶ç›˜ä»·ï¼ˆä¸å¤æƒï¼‰
                df['lt_mv'] = df['liqaShare_a'] * df['close_1'] # å¸‚å€¼ = å·²ä¸Šå¸‚æµé€šAè‚¡ * æ”¶ç›˜ä»·ï¼ˆä¸å¤æƒï¼‰
                df['lt_share_rate'] = df['liqaShare_a'] / df['totalShare_new'] #  æµé€šAè‚¡å æ¯”

                df['openinterest'] = 0
                df['date'] = pd.to_datetime(df['date'])
                # ä»·æ ¼æ¶¨è·Œå¹…åº¦
                df['price_limit'] = (df['close'] - df['open']) / df['open'] * 100

                # é€‰æ‹©éœ€è¦çš„åˆ—
                df = df[['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'turn', 'mv', 'lt_mv', 'lt_share_rate',   'is_st', 'profit_ttm_y', 'profit_y', 'revenue_y', 'roeAvg_y', 'profit_ttm_q', 'profit_q', 'revenue_single_q', 'roeAvg_q', 'price_limit', 'openinterest', ]]

                df.set_index('date', inplace=True)  # è®¾ç½® datetime ä¸ºç´¢å¼•
                df = df.sort_index()

                data_ = pd.merge(data, df, left_index=True, right_index=True, how='left')
                data_ = data_.sort_index()  # âœ… å¼ºåˆ¶å‡åº
                # æ£€æŸ¥å¹¶å¡«å……å…³é”®åˆ—
                # required_cols = ['datetime', 'open', 'high', 'low', 'close', 'volume', 'mv', 'lt_mv', 'lt_share_rate',  'profit', 'revenue', 'is_st']
                # for col in required_cols:
                #     if col not in df.columns:
                #         raise ValueError(f"ç¼ºå¤±å­—æ®µï¼š{col} in {stock_file}")
                # df = df[required_cols]

                # data_ = df.sort_index()
                data_.loc[:, ['volume', 'openinterest']] = data_.loc[:, ['volume', 'openinterest']].fillna(0)
                data_.loc[:, ['open', 'high', 'low', 'close']] = data_.loc[:, ['open', 'high', 'low', 'close', ]].bfill()
                data_.bfill(inplace=True)
                data_.fillna(0, inplace=True)
                rsub_cols = [ 'open', 'high', 'low', 'close', ]

                data_.dropna(subset=rsub_cols, inplace=True)

                # print("æœ€ç»ˆåˆå¹¶åçš„ data_ å½¢çŠ¶:", data_.shape)
                # print("ç¼ºå¤±å­—æ®µç»Ÿè®¡:\n", data_.isnull().sum())
                # print("close åˆ—å‰5è¡Œ:\n", data_['close'].head())

                # if df.empty or len(df) < 100:
                #     continue
                pandas_data = CustomPandasData(dataname=data_,
                                               fromdate=from_idx,
                                               todate=to_idx,
                                               timeframe=bt.TimeFrame.Days,
                                               name=stock_file.replace('.csv', ''))

                # data._name = stock_file.replace('.csv', '')  # è®¾ç½®æ•°æ®åç§°ï¼ˆç”¨äºåç»­åŒ¹é…æŒ‡æ•°åç­‰ï¼‰
                # print(f'æ·»åŠ æ•°æ®æºï¼š{data._name}ï¼Œæ•°æ®æ—¥æœŸèŒƒå›´ï¼š{df["datetime"].min()} ~ {df["datetime"].max()}ï¼Œå…± {len(df)} æ¡è®°å½•')
                datas.append(pandas_data)
            else:
                print(f'{stock_file} ç¼ºå°‘è´¢åŠ¡ä¿¡æ¯')
                # é€‰æ‹©éœ€è¦çš„åˆ—
                df_sorted = df_sorted[select_cols]
                for col in add_cols:
                    if col not in df_sorted.columns:
                        df_sorted[col] = 0

                df_sorted.set_index('date', inplace=True)  # è®¾ç½® datetime ä¸ºç´¢å¼•
                df_sorted = df_sorted.sort_index()
                data_ = pd.merge(data, df_sorted, left_index=True, right_index=True, how='left')
                data_.fillna(0, inplace=True)
                data_ = data_.sort_index()  # âœ… å¼ºåˆ¶å‡åº
                pandas_data = CustomPandasData(dataname=data_,
                                               fromdate=from_idx,
                                               todate=to_idx,
                                               timeframe=bt.TimeFrame.Days,
                                               name=stock_file.replace('.csv', ''))
                datas.append(pandas_data)

    return datas



def load_stock_data_df(from_idx, to_idx):
    """
    æ‰¹é‡åŠ è½½ data_dir ä¸‹çš„æ‰€æœ‰ CSV æ–‡ä»¶ï¼Œè¿”å›æ•°æ®åˆ—è¡¨
    æ–‡ä»¶åå°†ä½œä¸ºæ•°æ®åç§°æ³¨å…¥ï¼Œå¦‚ '600000.csv' -> data._name = '600000'
    :param data_dir: åŒ…å«CSVçš„è·¯å¾„
    :return: list of data feeds
    """
    zz_code_data_paths = [
        # '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/raw/index/ä¸­å°æ¿æŒ‡æ•°-ä¸­å°100-399005.csv',
        '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/raw/index/ä¸­å°ç»¼æŒ‡-399101.csv',
        # '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/raw/index/ä¸­è¯1000-000852.csv',
        # '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/raw/index/ä¸­è¯2000-932000.csv',
        # '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/raw/index/å¾®ç›˜è‚¡-BK1158.csv',
    ]
    zz_code_list = []
    for zz_code_data_path in zz_code_data_paths:
        if not os.path.exists(zz_code_data_path):
            print(f'{zz_code_data_path} ä¸å­˜åœ¨')
            continue
        zz_code_df = pd.read_csv(zz_code_data_path)
        zz_code_list += zz_code_df['type'].tolist()

    datas = []

    base_data_path = '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data'
    zh_data_dir = Path(base_data_path) / 'market'
    financial_data_dir = Path(base_data_path).parent / 'zh_data/financial'
    board_industry_dir = Path(base_data_path).parent / 'zh_data/industry/board_industry'


    # 1. æ‰¾åˆ°è¡Œä¸šç›®å½•ä¸­æœ€æ–°çš„CSVæ–‡ä»¶
    files = [f for f in os.listdir(board_industry_dir) if f.endswith('.csv')]
    if not files:
        raise FileNotFoundError(f"âš ï¸ è¡Œä¸šç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°CSVæ–‡ä»¶: {board_industry_dir}")
    files.sort(key=lambda f: os.path.getmtime(os.path.join(board_industry_dir, f)), reverse=True)
    latest_file = os.path.join(board_industry_dir, files[0])
    print(f"ğŸ“„ ä½¿ç”¨è¡Œä¸šæ–‡ä»¶: {latest_file}")

    # 2. è¯»å–è¡Œä¸šæ•°æ®
    industry_df = pd.read_csv(latest_file, dtype={'code': str})
    industry_df = industry_df[['code', 'name', 'industry_code', 'industry_name']]

    # è·å–æ‰€æœ‰æ—¶é—´æ•°æ®ï¼Œ ä½¿ç”¨000001.csv
    pdf = pd.read_csv(f'{zh_data_dir}/sh.000001/daily.csv')
    pdf['date'] = pd.to_datetime(pdf['date'])

    from_date = from_idx - timedelta(days=40)
    pdf = pdf[pdf['date'] >= from_date]
    data = pd.DataFrame(index=pdf['date'].unique())
    data = data.sort_index()

    select_cols = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', ]
    add_cols = ['industry_name', 'amount', 'turn', 'mv', 'lt_mv', 'lt_share_rate',   'is_st', 'profit_ttm_y', 'profit_y', 'revenue_y', 'roeAvg_y', 'profit_ttm_q', 'profit_q', 'revenue_single_q', 'roeAvg_q', 'openinterest', ]
    # åŠ è½½ SZ510880 SH159300
    etf_list = ['SZ510880', 'SH159919', 'SZ510050', 'SZ588000', 'SZ511880']
    etf_path = '/Users/dabai/liepin/study/llm/Financial_QA/src/busi/etf_/data/etf_trading/daily'
    for etf_code in etf_list:
        etf_df = pd.read_csv(f'{etf_path}/{etf_code}.csv')
        # é€‰æ‹©éœ€è¦çš„åˆ—
        etf_df = etf_df[select_cols]
        for col in add_cols:
            if col not in etf_df.columns:
                etf_df[col] = 0
        etf_df['date'] = pd.to_datetime(etf_df['date'])
        etf_df['date1'] = etf_df['date']
        etf_df.set_index('date', inplace=True)  # è®¾ç½® datetime ä¸ºç´¢å¼•
        etf_df = etf_df.sort_index()
        data_ = pd.merge(data, etf_df, left_index=True, right_index=True, how='left')
        data_.fillna(0, inplace=True)
        data_ = data_.sort_index()  # âœ… å¼ºåˆ¶å‡åº
        datas.append({'code': etf_code, 'data': data_})


    index_list =['csi932000', 'sz399101' , 'sh000905', 'sh000852', 'sh000046', 'sz399005', 'sz399008', 'sz399401',
                 'sz399649','sz399663','sz399377','sh000046','sz399408','sz399401','sh000991' ,
                 'sh000852', 'sz399004', 'sh000905', 'sz399006',
                 'sz399693']
    # è·å–æŒ‡æ•°æ•°æ®
    zz_path = '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/index'

    for index_code in index_list:

        zz_df = pd.read_csv(f'{zz_path}/{index_code}.csv')
        # é€‰æ‹©éœ€è¦çš„åˆ—
        zz_df = zz_df[select_cols[:-1]]
        for col in add_cols:
            if col not in zz_df.columns:
                zz_df[col] = 0
        zz_df['date'] = pd.to_datetime(zz_df['date'])
        zz_df['date1'] = zz_df['date']
        zz_df.set_index('date', inplace=True)  # è®¾ç½® datetime ä¸ºç´¢å¼•
        zz_df = zz_df.sort_index()
        data_ = pd.merge(data, zz_df, left_index=True, right_index=True, how='left')
        data_.fillna(0, inplace=True)
        data_ = data_.sort_index()  # âœ… å¼ºåˆ¶å‡åº
        datas.append({'code': index_code, 'data': data_})

    temp_stock_list = ['sh.000300',  'sh.000016', 'sh.000852', 'BK1158', ]
    for i, stock_file in enumerate(os.listdir(zh_data_dir)):
        # if i > 500:
        #     break

        # æµ‹è¯•
        # if len(datas) >100 and stock_file  not in temp_stock_list:
        #     continue

        # ä½¿ç”¨æŒ‡æ•°æˆåˆ†è‚¡è‚¡ç¥¨å›æµ‹
        if stock_file not in zz_code_list and stock_file not in temp_stock_list:
            print(f'è¿‡æ»¤éæŒ‡æ•°æˆåˆ†è‚¡è‚¡ç¥¨: {stock_file}')
            continue # 0.1945 sz399101æˆåˆ†è‚¡,
            # æŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ® 0.10   ä¸­è¯1000-000852ï¼Œä¸­è¯2000-932000
            # æŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ® 0.158  ä¸­å°ç»¼æŒ‡-399101,ä¸­è¯1000-000852ï¼Œä¸­è¯2000-932000
            # æŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ® 0.1945  ä¸­å°ç»¼æŒ‡-399101,ä¸­è¯1000-000852
            # æŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ® 0.158  ä¸­å°ç»¼æŒ‡-399101,ä¸­è¯2000-932000
            # æŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ® 0.10,ä¸­è¯2000-932000
        # 0.2137ï¼Œå…¨éƒ¨æ•°æ®
        # è¿‡æ»¤åˆ›ä¸šæ¿/ç§‘åˆ›æ¿/åŒ—äº¤æ‰€è‚¡ç¥¨
        if ('.30' in stock_file
                or '.68' in stock_file
                or '.8' in stock_file
                or '.4' in stock_file):
            print(f'è¿‡æ»¤åˆ›ä¸šæ¿/ç§‘åˆ›æ¿/åŒ—äº¤æ‰€è‚¡ç¥¨: {stock_file}')
            continue

        print(f'{i}/{stock_file}')
        # file_path = f'{zh_data_dir}/{stock_file}/daily.csv'
        file_path_a = f'{zh_data_dir}/{stock_file}/daily_a.csv'

        # è·å–è´¢åŠ¡ç›ˆåˆ©ä¿¡æ¯
        financial_path = f'{financial_data_dir}/{stock_file}/income.csv'
        income_gbjg_path = f'{financial_data_dir}/{stock_file}/income_gbjg.csv'
        if os.path.exists(file_path_a):
            df = pd.read_csv(file_path_a)
            if 'code' not in df.columns:
                print(f'{stock_file} ç¼ºå°‘åˆ—: {col}')
                df['code'] = stock_file

            # df = merge_stock_with_industry(df, industry_df)

            # è¿‡æ»¤ä¸Šå¸‚æ—¶é—´å¤ªçŸ­çš„è‚¡ç¥¨ ï¼ˆA è‚¡ä¸€å¹´äº¤æ˜“æ—¶é—´243å¤©ï¼‰ï¼Œå–ä¸Šå¸‚ä¸€å¹´å¤šçš„è‚¡ç¥¨
            if len(df) < 275:
                print(f'{stock_file} ä¸Šå¸‚äº¤æ˜“æ—¶é—´å¤ªçŸ­ï¼Œäº¤æ˜“çš„å¤©æ•°: {len(df)}ï¼Œå¿½ç•¥è¯¥è‚¡ç¥¨')
                continue

            # df_a = pd.read_csv(file_path_a)[['date','close']]
            # df_a.rename(columns={'close': 'close_1'}, inplace=True)

            # df = pd.merge(df, df_a, on='date', how='inner')
            df['close_1'] = df['close']

            # ä½¿ç”¨åå¤æƒä»·æ ¼ï¼Œfactorå‡è®¾ç½®ä¸º1ï¼Œ å›æµ‹ä½¿ç”¨è¯¥å› å­
            df['factor'] = 1.0
            # ç¡®ä¿ date åˆ—ä¸º datetime ç±»å‹å¹¶æ’åº
            df['date'] = pd.to_datetime(df['date'])
            df_sorted = df.sort_values('date')
            df_sorted.rename(columns={'isST': 'is_st', }, inplace=True)

            if os.path.exists(financial_path):

                financial_df = pd.read_csv(financial_path)
                if os.path.exists(income_gbjg_path):
                    income_gbjg_df = pd.read_csv(income_gbjg_path)[['å˜æ›´æ—¥æœŸ','æ€»è‚¡æœ¬', 'å·²ä¸Šå¸‚æµé€šAè‚¡']]
                    income_gbjg_df.rename(columns={'å˜æ›´æ—¥æœŸ': 'date', 'æ€»è‚¡æœ¬': 'totalShare_new', 'å·²ä¸Šå¸‚æµé€šAè‚¡': 'liqaShare_a'}, inplace=True)
                else:
                    income_gbjg_df = None

                quarterly_df, annual_df = process_financial_data(financial_df)

                df_temp = merge_with_stock(df_sorted, quarterly_df, annual_df, income_gbjg_df)
                if 'totalShare_new' not in df_temp.columns:
                    df_temp['totalShare_new'] = df_temp['totalShare_q']

                if 'liqaShare_a' not in df_temp.columns:
                    df_temp['liqaShare_a'] = df_temp['liqaShare_q']

                df2_sorted = df_temp.sort_values('date').ffill().dropna()

                df = df2_sorted

                df['mv'] = df['totalShare_new'] * df['close_1'] # å¸‚å€¼ = æ€»è‚¡æœ¬ * æ”¶ç›˜ä»·ï¼ˆä¸å¤æƒï¼‰
                df['lt_mv'] = df['liqaShare_a'] * df['close_1'] # å¸‚å€¼ = å·²ä¸Šå¸‚æµé€šAè‚¡ * æ”¶ç›˜ä»·ï¼ˆä¸å¤æƒï¼‰
                df['lt_share_rate'] = df['liqaShare_a'] / df['totalShare_new'] #  æµé€šAè‚¡å æ¯”

                df['openinterest'] = 0
                df['date'] = pd.to_datetime(df['date'])
                # ä»·æ ¼æ¶¨è·Œå¹…åº¦
                df['price_limit'] = (df['close'] - df['open']) / df['open'] * 100

                # é€‰æ‹©éœ€è¦çš„åˆ—
                df = df[['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'turn', 'mv', 'lt_mv', 'lt_share_rate',   'is_st', 'profit_ttm_y', 'profit_y', 'revenue_y', 'roeAvg_y', 'profit_ttm_q', 'profit_q', 'revenue_single_q', 'roeAvg_q', 'price_limit', 'openinterest', ]]
                df['date1'] = df['date']
                df.set_index('date', inplace=True)  # è®¾ç½® datetime ä¸ºç´¢å¼•
                df = df.sort_index()

                data_ = pd.merge(data, df, left_index=True, right_index=True, how='left')
                data_ = data_.sort_index()  # âœ… å¼ºåˆ¶å‡åº
                # æ£€æŸ¥å¹¶å¡«å……å…³é”®åˆ—
                # required_cols = ['datetime', 'open', 'high', 'low', 'close', 'volume', 'mv', 'lt_mv', 'lt_share_rate',  'profit', 'revenue', 'is_st']
                # for col in required_cols:
                #     if col not in df.columns:
                #         raise ValueError(f"ç¼ºå¤±å­—æ®µï¼š{col} in {stock_file}")
                # df = df[required_cols]

                # data_ = df.sort_index()
                data_.loc[:, ['volume', 'openinterest']] = data_.loc[:, ['volume', 'openinterest']].fillna(0)
                data_.loc[:, ['open', 'high', 'low', 'close']] = data_.loc[:, ['open', 'high', 'low', 'close', ]].bfill()
                data_.bfill(inplace=True)
                data_.fillna(0, inplace=True)
                rsub_cols = [ 'open', 'high', 'low', 'close', ]

                data_.dropna(subset=rsub_cols, inplace=True)

                # print("æœ€ç»ˆåˆå¹¶åçš„ data_ å½¢çŠ¶:", data_.shape)
                # print("ç¼ºå¤±å­—æ®µç»Ÿè®¡:\n", data_.isnull().sum())
                # print("close åˆ—å‰5è¡Œ:\n", data_['close'].head())

                # if df.empty or len(df) < 100:
                #     continue

                # data._name = stock_file.replace('.csv', '')  # è®¾ç½®æ•°æ®åç§°ï¼ˆç”¨äºåç»­åŒ¹é…æŒ‡æ•°åç­‰ï¼‰
                # print(f'æ·»åŠ æ•°æ®æºï¼š{data._name}ï¼Œæ•°æ®æ—¥æœŸèŒƒå›´ï¼š{df["datetime"].min()} ~ {df["datetime"].max()}ï¼Œå…± {len(df)} æ¡è®°å½•')
                datas.append({'code': stock_file, 'data': data_})
            else:
                print(f'{stock_file} ç¼ºå°‘è´¢åŠ¡ä¿¡æ¯')
                # é€‰æ‹©éœ€è¦çš„åˆ—
                df_sorted = df_sorted[select_cols]
                for col in add_cols:
                    if col not in df_sorted.columns:
                        df_sorted[col] = 0

                df_sorted['date1'] = df_sorted['date']
                df_sorted.set_index('date', inplace=True)  # è®¾ç½® datetime ä¸ºç´¢å¼•
                df_sorted = df_sorted.sort_index()
                data_ = pd.merge(data, df_sorted, left_index=True, right_index=True, how='left')
                data_.fillna(0, inplace=True)
                data_ = data_.sort_index()  # âœ… å¼ºåˆ¶å‡åº


                datas.append({'code': stock_file, 'data': data_})

    return datas

