import random

import akshare as ak
from datetime import datetime
import time

import pandas as pd
import os
import glob


def compute_industry_rise_fall() -> pd.DataFrame:
    """
    å‚æ•°ï¼š
    - industry_file: è‚¡ç¥¨è¡Œä¸šå½’å±ž CSV æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å« code, industry_name, dateï¼‰
    - quote_dir: è‚¡ç¥¨è¡Œæƒ…æ•°æ®æ–‡ä»¶å¤¹ï¼ˆæ¯ä¸ªæ–‡ä»¶å¦‚ 20250710.csvï¼‰
    - output_file: ä¿å­˜ç»Ÿè®¡ç»“æžœçš„è·¯å¾„
    """

    # æ›¿æ¢ä¸ºä½ éœ€è¦çš„ç›®å½•è·¯å¾„
    directory = "/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/industry/board_industry"
    # ä½¿ç”¨ glob èŽ·å–æ‰€æœ‰ csv æ–‡ä»¶
    files = glob.glob(os.path.join(directory, "*.csv"))
    # æŒ‰ç…§ä¿®æ”¹æ—¶é—´æŽ’åºï¼Œå–æœ€æ–°çš„ä¸€ä¸ª
    latest_file = max(files, key=os.path.getmtime)

    print(f"ðŸ“ æœ€æ–°æ–‡ä»¶: {latest_file}")

    # è¯»å–æœ€æ–°æ–‡ä»¶åˆ° DataFrame
    industry_df = pd.read_csv(latest_file, dtype={'code': str})
    industry_df = industry_df[['code', 'name', 'industry_name', 'industry_code']]

    quote_dir: str = '/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/market'
    all_results = []

    for fname in sorted(os.listdir(quote_dir)):
        if '.' not in fname:
            print(f"âš ï¸ æ–‡ä»¶ {fname} æ— æ•ˆ")
            continue
        code_str = fname.split('.')[1]

        # åŠ è½½å½“æ—¥è¡Œæƒ…æ•°æ®
        quote_df = pd.read_csv(os.path.join(quote_dir, f'{fname}/daily_a.csv') )
        quote_df['code'] = code_str
        quote_df = quote_df[['code', 'open', 'close', 'date']]
        quote_df = quote_df[quote_df['open'] > 0]  # æŽ’é™¤å¼€ç›˜ä¸º0çš„æ— æ•ˆæ•°æ®
        quote_df['pct'] = (quote_df['close'] - quote_df['open']) / quote_df['open'] * 100

        # åˆå¹¶è¡Œä¸šæ•°æ®
        merged = pd.merge(quote_df, industry_df, on=['code'], how='inner')

        # åŽ»é™¤æ²¡æœ‰è¡Œä¸šä¿¡æ¯çš„
        merged = merged.dropna(subset=['industry_name', 'code'])
        all_results.append( merged )

    all_data = pd.concat(all_results, ignore_index=True)
    all_results = []
    # åˆ†ç»„ç»Ÿè®¡
    for group_index, group in all_data.groupby([ 'date', 'industry_name',]):
        date1, ind_name = group_index[0], group_index[1]
        total = len(group)
        up = (group['pct'] > 0).sum()
        down = (group['pct'] < 0).sum()
        limit_up = (group['pct'] > 9.8).sum()
        limit_down = (group['pct'] < -9.8).sum()
        up_1 = (group['pct'] > 1).sum()
        up_2 = (group['pct'] > 2).sum()
        down_2 = (group['pct'] < -2).sum()
        up_5 = (group['pct'] > 5).sum()
        down_5 = (group['pct'] < -5).sum()
        all_results.append({
            'date': date1,
            'industry': ind_name,
            'total': total,
            'up_rate': up/total,
            'up': up,
            'down': down,
            'limit_up': limit_up,
            'limit_down': limit_down,
            'up_1pct': up_1,
            'up_2pct': up_2,
            'up_5pct': up_5,
            'up_1pct_rate': up_1 / total,
            'up_2pct_rate': up_2 / total,
            'up_5pct_rate': up_5 / total,
            'down_2pct': down_2,
            'down_5pct': down_5,
        })


    # ä¿å­˜ç»“æžœ
    result_df = pd.DataFrame(all_results)
    # result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    # print(f"âœ… è¡Œä¸šæ¶¨è·Œç»Ÿè®¡å·²ä¿å­˜ï¼š{output_file}")
    return result_df


def save_all_stock_industry_map():
    base_path = "/Users/dabai/liepin/study/llm/Financial_QA/data/zh_data/industry"
    if not os.path.exists(base_path):
        os.makedirs(base_path)
    board_industry_base_path = f"{base_path}/industry_flow"
    if not os.path.exists(board_industry_base_path):
        os.makedirs(board_industry_base_path)
    # å½“å‰æ—¥æœŸ
    today_str = datetime.today().strftime("%Y%m%d")

    # èŽ·å–è¡Œä¸šåˆ—è¡¨
    industry_df = ak.stock_board_industry_name_em()
    industry_list = industry_df.to_dict('records')

    result = []

    for item in industry_list:
        industry_name = item['æ¿å—åç§°']
        industry_code = item['æ¿å—ä»£ç ']
        try:

            # èŽ·å–è¡Œä¸šåŽ†å²èµ„é‡‘æµ
            cons_df = ak.stock_sector_fund_flow_hist(symbol=industry_name)

            cons_df['è¡Œä¸šä»£ç '] = industry_code
            cons_df['è¡Œä¸šåç§°'] = industry_name
            cons_df.to_csv(f"{board_industry_base_path}/{industry_name}.csv", index=False, encoding='utf-8-sig')
            result.append(cons_df)
            print(f"âœ… {industry_name} èŽ·å–æˆåŠŸï¼Œå…± {len(cons_df)} æ¡")
            time.sleep(random.randint(1, 5))  # é˜²æ­¢è¯·æ±‚å¤ªå¿«è¢«å°
        except Exception as e:
            print(f"âš ï¸ èŽ·å– {industry_name} å¤±è´¥ï¼š{e}")

    result_df = pd.concat(result, ignore_index=True)
    result_df.to_csv(f"{base_path}/industry_flow.csv", index=False, encoding='utf-8-sig')
    print(f"\nðŸ“ å·²ä¿å­˜åˆ°æ–‡ä»¶: {base_path}/industry_flow.csvï¼Œå…± {len(result_df)} æ¡")

    industry_rise_df = compute_industry_rise_fall()
    industry_rise_df.to_csv(f"{base_path}/industry_stock_stat.csv", index=False, encoding='utf-8-sig')
    print(f"\nðŸ“ å·²ä¿å­˜åˆ°æ–‡ä»¶: {base_path}/industry_stock_stat.csvï¼Œå…± {len(industry_rise_df)} æ¡")

    # ç¡®ä¿ç”¨äºŽå…³è”çš„å­—æ®µæ˜¯å­—ç¬¦ä¸²ç±»åž‹
    result_df['æ—¥æœŸ'] = result_df['æ—¥æœŸ'].astype(str)
    result_df['è¡Œä¸šåç§°'] = result_df['è¡Œä¸šåç§°'].astype(str)

    industry_rise_df['date'] = industry_rise_df['date'].astype(str)
    industry_rise_df['industry'] = industry_rise_df['industry'].astype(str)

    # å†è¿›è¡Œåˆå¹¶
    merge_result = pd.merge(
        result_df,
        industry_rise_df,
        left_on=['æ—¥æœŸ', 'è¡Œä¸šåç§°'],
        right_on=['date', 'industry'],
        how='left'
    )

    merge_result.to_csv(f"{base_path}/industry_flow_merge.csv", index=False, encoding='utf-8-sig')
    print(f"\nðŸ“ å·²ä¿å­˜åˆ°æ–‡ä»¶: {base_path}/industry_flow_merge.csvï¼Œå…± {len(merge_result)} æ¡")


if __name__ == '__main__':

    save_all_stock_industry_map()
    # compute_industry_rise_fall()

